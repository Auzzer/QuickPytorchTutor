{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QuickPytorchTutor.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DAknU9WCkuqU",
        "mfivPcEtj6xv",
        "Jhf_3MDZk4Lt",
        "6S6iMV6lzhnI",
        "_VKnbJy7_Cq_",
        "AeZjrn1RzjuG"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPLRUwxQhDG2IQnoBTk5DbV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Auzzer/QuickPytorchTutor/blob/main/QuickPytorchTutor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjsadXRuj12S"
      },
      "source": [
        "# Tensor (张量)的创建与基本操作\n",
        "张量是GPU运算中常见的数据类型，类似于Numpy中的矩阵，但是由于深度学习中常常需要使用GPU进行并行运算，提升计算速度，因此使用Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAknU9WCkuqU"
      },
      "source": [
        "## 创建"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZlmxcMRjhR1"
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ig-ZWsc6kfzD",
        "outputId": "69f70fd6-d340-44cb-f27c-6312021421d7"
      },
      "source": [
        "# 创建一个张量通常需要初始化，我们一般使用：\n",
        "x1 = torch.empty(5, 3) #一个5x3的张量\n",
        "print(x1)\n",
        "\n",
        "# 随机初始化张量\n",
        "x2 = torch.rand(5, 3)\n",
        "print(x2)\n",
        "\n",
        "# 在初始化张量时，有时需要指定数据类型：\n",
        "x3 = torch.zeros(5, 3, dtype=torch.long) #创建一个数据类型为long的\"0\"填充矩阵\n",
        "print(x3)\n",
        "\n",
        "# 如果已知一个矩阵，将其转化为张量加速计算\n",
        "x4 = torch.tensor([[1,2,3],[6,7,8]]) \n",
        "print(x4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.3773e+24, 3.0725e-41, 2.8026e-45],\n",
            "        [0.0000e+00, 4.2039e-45, 0.0000e+00],\n",
            "        [8.4078e-45, 0.0000e+00, 9.8091e-45],\n",
            "        [0.0000e+00, 1.1210e-44, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
            "tensor([[0.6326, 0.1925, 0.2692],\n",
            "        [0.3430, 0.6707, 0.9599],\n",
            "        [0.9630, 0.5290, 0.7859],\n",
            "        [0.8153, 0.7201, 0.8248],\n",
            "        [0.7111, 0.5788, 0.2456]])\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "tensor([[1, 2, 3],\n",
            "        [6, 7, 8]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBQL0ZvouIbW",
        "outputId": "a3189830-993f-41fe-c096-182a3660c272"
      },
      "source": [
        "# 获取size\n",
        "print(x4.size()) # 结果表示为两行三列"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfivPcEtj6xv"
      },
      "source": [
        "## Basic Product\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhcpNne0v146"
      },
      "source": [
        "### 加法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AEOQiMQk0C8",
        "outputId": "4dfece58-2a68-4605-89c9-3d6d9e2316a3"
      },
      "source": [
        "# 对于一个最简单的加法\n",
        "x = torch.rand(5, 3)\n",
        "y = torch.rand(5, 3)\n",
        "print (x+y)\n",
        "# 或者\n",
        "print (torch.add(x, y))\n",
        "\n",
        "# 对于torch.add(),有一个option可以将结果保存下来,但是首先需要将结果初始化\n",
        "result = torch.empty(5, 3)\n",
        "torch.add(x, y, out = result)\n",
        "print(\"result: \\n\",result)\n",
        "\n",
        "#特别值得注意的是，torch.add()函数只能对两个张量进行运算，当数量大于二的时候：\n",
        "y1 = torch.zeros(5, 3)\n",
        "y2 = torch.empty(5, 3)\n",
        "for i in range(0, 5):\n",
        "  xi = torch.rand(5, 3)\n",
        "  y1.add(xi)\n",
        "  y2.add(xi)\n",
        "\n",
        "print(\"y1\\n\",y1)\n",
        "print(\"y2\\n\",y2)\n",
        "# 结果显示在做加法的时候，由于empty张量会随机给一个值，所以应该使用\"zeros张量\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.8637, 0.8841, 0.3732],\n",
            "        [0.6292, 1.1238, 1.2939],\n",
            "        [1.1554, 0.9996, 0.8031],\n",
            "        [1.7773, 1.0039, 1.4080],\n",
            "        [0.8788, 0.7864, 0.7202]])\n",
            "tensor([[1.8637, 0.8841, 0.3732],\n",
            "        [0.6292, 1.1238, 1.2939],\n",
            "        [1.1554, 0.9996, 0.8031],\n",
            "        [1.7773, 1.0039, 1.4080],\n",
            "        [0.8788, 0.7864, 0.7202]])\n",
            "tensor([[1.8637, 0.8841, 0.3732],\n",
            "        [0.6292, 1.1238, 1.2939],\n",
            "        [1.1554, 0.9996, 0.8031],\n",
            "        [1.7773, 1.0039, 1.4080],\n",
            "        [0.8788, 0.7864, 0.7202]])\n",
            "y1\n",
            " tensor([[2.5804, 1.9542, 2.7683],\n",
            "        [2.3748, 2.7451, 1.6035],\n",
            "        [2.7108, 2.4057, 2.3366],\n",
            "        [3.9157, 2.9352, 2.8133],\n",
            "        [3.1810, 2.2222, 1.8287]])\n",
            "y2\n",
            " tensor([[4.3765e+24, 1.9542e+00, 5.1006e+00],\n",
            "        [5.0222e+00, 4.9549e+00, 3.1798e+00],\n",
            "        [4.7230e+00, 4.3089e+00, 3.9306e+00],\n",
            "        [7.3395e+00, 4.5747e+00, 4.9997e+00],\n",
            "        [5.2263e+00, 4.3514e+00, 4.5425e+00]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnVEnYjsyuBR"
      },
      "source": [
        "### 乘法\n",
        "在矩阵中，乘法有点乘和叉乘两种，张量也有相对应的不同计算方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_Pe1mhsy9-b",
        "outputId": "51af165a-02fd-4112-d4a5-50d288fa062d"
      },
      "source": [
        "# 点乘\n",
        "x1 = torch.rand(5, 3)\n",
        "x2 = torch.rand(5, 3)\n",
        "y = torch.mul(x1, x2)# 类似与上文的add，在多个张量可以使用x1.mul(x2)\n",
        "print(\"x1:\\n\", x1, \"\\n x2:\\n\", x2, \"\\n y:\\n\",y)\n",
        "\n",
        "# 叉乘\n",
        "x1 = torch.rand(2, 3)\n",
        "x2 = torch.rand(3, 4)\n",
        "y = torch.mm(x1, x2)# 类似与上文的add，在多个张量可以使用x1.mm(x2)\n",
        "print(\"x1:\\n\", x1, \"\\nx2:\\n\", x2, \"\\ny:\\n\",y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x1:\n",
            " tensor([[3.4130e-01, 7.1896e-01, 4.0122e-01],\n",
            "        [4.4395e-01, 4.7499e-01, 9.2966e-01],\n",
            "        [6.5652e-02, 4.7017e-01, 7.5633e-01],\n",
            "        [7.3802e-01, 1.7166e-01, 4.6248e-01],\n",
            "        [4.1113e-01, 2.7661e-01, 1.5497e-04]]) \n",
            " x2:\n",
            " tensor([[0.0041, 0.5140, 0.0541],\n",
            "        [0.7816, 0.9990, 0.2608],\n",
            "        [0.2597, 0.0236, 0.2706],\n",
            "        [0.7921, 0.0189, 0.5529],\n",
            "        [0.7623, 0.7521, 0.1769]]) \n",
            " y:\n",
            " tensor([[1.4121e-03, 3.6954e-01, 2.1710e-02],\n",
            "        [3.4698e-01, 4.7453e-01, 2.4249e-01],\n",
            "        [1.7049e-02, 1.1105e-02, 2.0468e-01],\n",
            "        [5.8458e-01, 3.2442e-03, 2.5570e-01],\n",
            "        [3.1339e-01, 2.0804e-01, 2.7414e-05]])\n",
            "x1:\n",
            " tensor([[0.0552, 0.9164, 0.2524],\n",
            "        [0.0760, 0.2871, 0.9371]]) \n",
            "x2:\n",
            " tensor([[0.5551, 0.5035, 0.2915, 0.4963],\n",
            "        [0.2515, 0.5803, 0.8617, 0.6428],\n",
            "        [0.6847, 0.6481, 0.6611, 0.2976]]) \n",
            "y:\n",
            " tensor([[0.4339, 0.7231, 0.9726, 0.6915],\n",
            "        [0.7560, 0.8122, 0.8891, 0.5011]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6mEi_L_58zQ"
      },
      "source": [
        "### Numpy中的对应与转化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aio6cWJ63gDh"
      },
      "source": [
        "#### 索引\n",
        "torch支持使用类似于Numpy中的索引对张量进行操作\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVOpdct03fK0",
        "outputId": "fb11d838-cf3c-4d93-8264-6e97b4342bcf"
      },
      "source": [
        "x = torch.tensor([[1,2,3],[3,4,5]])\n",
        "print(x[:,0])\n",
        "print(x[1,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 3])\n",
            "tensor([3, 4, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3cygC_r5wiA"
      },
      "source": [
        "#### 在numpy中reshape对应"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27uYpMdW6MbV",
        "outputId": "474942df-b0d7-4202-b90d-c39f3c45901c"
      },
      "source": [
        "x = torch.randn(5, 3)\n",
        "y = x.view(3, 5)\n",
        "z = x.view(-1, 5) # 当选项中有一个-1时候，代表从另外一个维度考虑转化方式\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2350, -0.7981, -1.3963],\n",
            "        [-0.5878,  0.7670,  1.4030],\n",
            "        [ 0.1570, -1.0562,  1.8708],\n",
            "        [-0.3263,  1.8232, -0.2369],\n",
            "        [ 0.1883,  1.0110, -0.3872]])\n",
            "tensor([[ 0.2350, -0.7981, -1.3963, -0.5878,  0.7670],\n",
            "        [ 1.4030,  0.1570, -1.0562,  1.8708, -0.3263],\n",
            "        [ 1.8232, -0.2369,  0.1883,  1.0110, -0.3872]])\n",
            "tensor([[ 0.2350, -0.7981, -1.3963, -0.5878,  0.7670],\n",
            "        [ 1.4030,  0.1570, -1.0562,  1.8708, -0.3263],\n",
            "        [ 1.8232, -0.2369,  0.1883,  1.0110, -0.3872]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nJJsSoI84R5"
      },
      "source": [
        "### 覆盖操作\n",
        "任何以\"_\"结尾的函数（操作）都会替换原来的变量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkXlm9j29Kal",
        "outputId": "56276c3c-90c3-4d01-e8e8-87708a87fe34"
      },
      "source": [
        "x1 = torch.rand(5, 3)\n",
        "print(\"覆盖以前的x1:\\n\", x1)\n",
        "x2 = torch.rand(5, 3)\n",
        "y = x1.add_(x2)\n",
        "print(\"覆盖以后的x1:\\n\", x1)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "覆盖以前的x1:\n",
            " tensor([[0.4530, 0.5302, 0.8162],\n",
            "        [0.1162, 0.3626, 0.5144],\n",
            "        [0.5313, 0.8675, 0.4438],\n",
            "        [0.4011, 0.6296, 0.2395],\n",
            "        [0.4407, 0.7304, 0.2312]])\n",
            "覆盖以后的x1:\n",
            " tensor([[0.5994, 0.6711, 0.9561],\n",
            "        [0.5438, 0.8049, 0.7759],\n",
            "        [0.7994, 1.4201, 1.2093],\n",
            "        [1.3453, 0.9124, 0.2621],\n",
            "        [1.1335, 0.8059, 0.5170]])\n",
            "tensor([[0.5994, 0.6711, 0.9561],\n",
            "        [0.5438, 0.8049, 0.7759],\n",
            "        [0.7994, 1.4201, 1.2093],\n",
            "        [1.3453, 0.9124, 0.2621],\n",
            "        [1.1335, 0.8059, 0.5170]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyRe1bB96GIy"
      },
      "source": [
        "可以看到x1的值发生了变化,但是和y的值是一样的<br>\n",
        "更多对于tensor的operation可以参考官方文档：https://pytorch.org/docs/stable/torch.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhf_3MDZk4Lt"
      },
      "source": [
        "## Cuda加速\n",
        "在这里我们先提出一个概念：\n",
        "为了计算加速，有一些数据可以被放入cuda中加速计算。<br>\n",
        "在这里我们先将tensor放入cuda中，第一步需要先判定是否有cuda(GPU)可以使用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkSHA4gKlBAp",
        "outputId": "bcd5b621-a4ef-4aba-98b6-67c5a5985be4"
      },
      "source": [
        "import torch\n",
        "x = torch.rand(5, 3)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 下面分别从cuda中直接生成tensor以及将tensor生成后放进cuda中\n",
        "x = x.to(device)\n",
        "y = torch.ones_like(x, device=device)\n",
        "z = x + y\n",
        "print(z)\n",
        "print(z.to(\"cpu\", torch.double))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.6126, 1.0080, 1.1237],\n",
            "        [1.8539, 1.9998, 1.7423],\n",
            "        [1.0243, 1.2125, 1.4499],\n",
            "        [1.1781, 1.6726, 1.6787],\n",
            "        [1.4428, 1.1803, 1.5834]])\n",
            "tensor([[1.6126, 1.0080, 1.1237],\n",
            "        [1.8539, 1.9998, 1.7423],\n",
            "        [1.0243, 1.2125, 1.4499],\n",
            "        [1.1781, 1.6726, 1.6787],\n",
            "        [1.4428, 1.1803, 1.5834]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx-3siwizYOp"
      },
      "source": [
        "# 神经网络训练\n",
        "对于一个神经网络而言，一般都会有\n",
        "\n",
        "1.   数据处理\n",
        "2.   定义网络\n",
        "3.   训练策略\n",
        "4.   可视化\n",
        "5.   Pre-train & Fine-Tune(可选) <br>\n",
        "\n",
        "这几个部分，接下来我们将逐一介绍\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S6iMV6lzhnI"
      },
      "source": [
        "## 数据处理\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPYyc6wy_AWE"
      },
      "source": [
        "### 数据加载"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgQ27Wk5ADLk"
      },
      "source": [
        "在进行对比实验时，经常需要公用数据集，torch内置了几个常用数据集包括：\n",
        "\n",
        "* MNIST\n",
        "* ImageNet\n",
        "* COCO\n",
        "* CIFAR <br>\n",
        "\n",
        "等等....<br>\n",
        "我们只需要调用torchvision中的torchvision.datasets就可以使用它，他的安装方式是：\n",
        "\n",
        "\n",
        "```\n",
        "pip install torchvision\n",
        "```\n",
        "torchvision.datasets 可以理解为PyTorch团队自定义的dataset，这些dataset帮我们提前处理好了很多的图片数据集，我们拿来就可以直接使用,具体使用方式如下：\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbebLkcDAEX_"
      },
      "source": [
        "import torchvision.datasets as datasets\n",
        "\n",
        "trainset = datasets.MNIST(root=\"./data\",\n",
        "              train=True,# True为训练集，False为测试集\n",
        "              download=True, #表示是否需要下载数据集\n",
        "              transform=None) #是否对其进行数据增广\n",
        "validset = datasets.MNIST(root=\"./data\", train=True, download=False, transform=None)        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emzhThi3CL6l"
      },
      "source": [
        "在很多时候，我们也需要自定义数据集去完成我们需要的任务，接下来介绍如何进行操作"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu6QgsKmXXR9"
      },
      "source": [
        "在Pytorch中为了便于调用函数（因为通常在文件过大的时候会将不同部分拆分成为几个python脚本），我们通常需要声明类。对于数据加载的类编写方式如下：其主要分为两步：1. 数据集定义 2. 数据加载器 <br>\n",
        "注：为了方便起见，使用kaggle上的[bluebook for bulldozers](https://www.kaggle.com/c/bluebook-for-bulldozers/data)举例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57gyXGg0XRFK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VKnbJy7_Cq_"
      },
      "source": [
        "### 数据预处理\n",
        "一般来说，即便是对于ImageNet这样大型数据集也需要进行数据增广(data augementation)，在torchvision中的transforms模块内置了大量的操作，这里我们只进行简单举例，更多可以访问transforms操作文件。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOrSnzv0bozY"
      },
      "source": [
        "from torchvision import transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  #先四周填充0，在把图像随机裁剪成32*32\n",
        "    transforms.RandomHorizontalFlip(),  #图像一半的概率翻转，一半的概率不翻转\n",
        "    transforms.RandomRotation((-45,45)), #随机旋转\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)), #R,G,B每层的归一化用到的均值和方差\n",
        "])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnpQfXllbqog"
      },
      "source": [
        "接下来我们只需要对数据数据加载部分进行简单修改即可"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byDfMqSmboxk"
      },
      "source": [
        "trainset = datasets.MNIST(root=\"./data\", train=True, download=False, transform= transform)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GBlvogEdHZ0"
      },
      "source": [
        "由于Pytorch中以及包含了MNIST数据集，也可以直接使用DataLoader对数据进行读取。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09B_Qf93dYli"
      },
      "source": [
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('./data', train=True, download=True, \n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),# 将读取的数据转化为张量方便计算\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))#这一部分来源于前人根据这个数据集获得的标准化参数，不同的数据集不同\n",
        "                       ])),\n",
        "                       ])),\n",
        "        batch_size=512, #这里的batch_size将在下文的训练策略中详细介绍\n",
        "        shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afvjdl8yhSlO"
      },
      "source": [
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('data', train=False, transform=transforms.Compose([\n",
        "                           transforms.ToTensor(), \n",
        "                           transforms.Normalize((0.1307,), (0.3081,)) \n",
        "        batch_size=512, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeZjrn1RzjuG"
      },
      "source": [
        "## 定义网络"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Dwet6scTGI"
      },
      "source": [
        "正如上文对数据调用时声明类一样，建议使用类定义网网络：                                                          \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR_niT3Fl7Lr"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn # 定义网络\n",
        "import torch.nn.functional as F #网络中的操作，如卷积、padding通常在这个里面"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LenDw2tkjXq"
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # batch*1*28*28（每次会送入batch个样本，输入通道数1（黑白图像），图像分辨率是28x28）\n",
        "        # 下面的卷积层Conv2d的第一个参数指输入通道数，第二个参数指输出通道数，第三个参数指卷积核的大小\n",
        "        self.conv1 = nn.Conv2d(1, 10, 5) # 输入通道数1，输出通道数10，核的大小5\n",
        "        self.conv2 = nn.Conv2d(10, 20, 3) # 输入通道数10，输出通道数20，核的大小3\n",
        "        # 下面的全连接层Linear的第一个参数指输入通道数，第二个参数指输出通道数\n",
        "        self.fc1 = nn.Linear(20*10*10, 500) # 输入通道数是2000，输出通道数是500\n",
        "        self.fc2 = nn.Linear(500, 10) # 输入通道数是500，输出通道数是10，即10分类\n",
        "    def forward(self,x):\n",
        "        in_size = x.size(0) # 在本例中in_size=512，也就是BATCH_SIZE的值。输入的x可以看成是512*1*28*28的张量。\n",
        "        x = self.conv1(x) # batch*1*28*28 -> batch*10*24*24（28x28的图像经过一次核为5x5的卷积，输出变为24x24）\n",
        "        x = F.relu(x) # batch*10*24*24（激活函数ReLU不改变形状））\n",
        "        x = F.max_pool2d(x, 2, 2) # batch*10*24*24 -> batch*10*12*12（2*2的池化层会减半）\n",
        "        x = self.conv2(x) # batch*10*12*12 -> batch*20*10*10（再卷积一次，核的大小是3）\n",
        "        x = F.relu(x) # batch*20*10*10\n",
        "        x = x.view(in_size, -1) # batch*20*10*10 -> batch*2000（out的第二维是-1，说明是自动推算，本例中第二维是20*10*10）\n",
        "        x = self.fc1(x) # batch*2000 -> batch*500\n",
        "        x = F.relu(x) # batch*500\n",
        "        x = self.fc2(x) # batch*500 -> batch*10\n",
        "        x = F.log_softmax(x, dim=1) # 计算log(softmax(x))\n",
        "        return x"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiiRD2Kexkzv"
      },
      "source": [
        "正如上文所说的，tensor放入cuda中可以加速运算，这里也适用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hNdGrXHxjp2",
        "outputId": "c29a1d15-6c78-4ea7-fe10-7a7bccddfe7e"
      },
      "source": [
        "# 依然按照上文的方法来判断是否有cuda可以使用\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ConvNet().to(device)\n",
        "print(model)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvNet(\n",
            "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=2000, out_features=500, bias=True)\n",
            "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlbYhHHFz5VG"
      },
      "source": [
        "很多情况下，我们需要分析模型的复杂度，需要通过查看模型的参数个数来看"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz6Ng7Xiz4wu"
      },
      "source": [
        "for parameters in ConvNet().parameters(): \n",
        "#注意，在部分程序中，有人会将定义好的神经网络存储到net中，这是这个net是一个类，parameters这个函数必须跟一个类，而不是一个函数名名称\n",
        "#比方说这里ConvNet.parametrics()就是错误的，因为ConvNet()才是一个类\n",
        "    print(parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpvvi6_NznL7"
      },
      "source": [
        "## 训练策略"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2m3KvdhzqmJ"
      },
      "source": [
        "### 求导机制"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSQsXDx1ztcI"
      },
      "source": [
        "### 学习率设置"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huMlUdeEzwqO"
      },
      "source": [
        "### Batch设置"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjWLw9_gz3EW"
      },
      "source": [
        "## 可视化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQRpD4va0NQZ"
      },
      "source": [
        "### 本地保存"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW_ew5qL0RBU"
      },
      "source": [
        "### 利用TensorBoardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpQ2prYv0crk"
      },
      "source": [
        "## Pre-Train & Fine-Tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWAN4vsczmq-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deVkr1thzgQK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}